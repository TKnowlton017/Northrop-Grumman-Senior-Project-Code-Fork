{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ab05d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f33601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea11915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the zarr_dataset\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"../../../prediction-dataset/\"\n",
    "cfg = load_config_data(\"./visualisation_config.yaml\")\n",
    "dm = LocalDataManager()\n",
    "dataset_path = dm.require(cfg[\"val_data_loader\"][\"key\"])\n",
    "zarr_dataset = ChunkedDataset(dataset_path)\n",
    "zarr_dataset.open()\n",
    "\n",
    "# using EgoDataset interface to extract AV data\n",
    "rast = build_rasterizer(cfg, dm)\n",
    "ego_dataset = EgoDataset(cfg, zarr_dataset, rast)\n",
    "# agent_dataset = AgentDataset(cfg, zarr_dataset, rast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c971117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0   248]\n",
      " [  248   497]\n",
      " [  497   746]\n",
      " [  746   995]\n",
      " [  995  1244]\n",
      " [ 1244  1493]\n",
      " [ 1493  1742]\n",
      " [ 1742  1991]\n",
      " [ 1991  2240]\n",
      " [ 2240  2489]\n",
      " [ 2489  2738]\n",
      " [ 2738  2987]\n",
      " [ 2987  3236]\n",
      " [ 3236  3485]\n",
      " [ 3485  3734]\n",
      " [ 3734  3983]\n",
      " [ 3983  4232]\n",
      " [ 4232  4481]\n",
      " [ 4481  4730]\n",
      " [ 4730  4979]\n",
      " [ 4979  5228]\n",
      " [ 5228  5477]\n",
      " [ 5477  5725]\n",
      " [ 5725  5973]\n",
      " [ 5973  6221]\n",
      " [ 6221  6469]\n",
      " [ 6469  6717]\n",
      " [ 6717  6965]\n",
      " [ 6965  7213]\n",
      " [ 7213  7461]\n",
      " [ 7461  7709]\n",
      " [ 7709  7957]\n",
      " [ 7957  8205]\n",
      " [ 8205  8453]\n",
      " [ 8453  8701]\n",
      " [ 8701  8949]\n",
      " [ 8949  9197]\n",
      " [ 9197  9445]\n",
      " [ 9445  9693]\n",
      " [ 9693  9941]\n",
      " [ 9941 10189]\n",
      " [10189 10437]\n",
      " [10437 10685]\n",
      " [10685 10933]\n",
      " [10933 11182]\n",
      " [11182 11431]\n",
      " [11431 11680]\n",
      " [11680 11929]\n",
      " [11929 12177]\n",
      " [12177 12425]\n",
      " [12425 12673]\n",
      " [12673 12921]\n",
      " [12921 13169]\n",
      " [13169 13417]\n",
      " [13417 13665]\n",
      " [13665 13913]\n",
      " [13913 14161]\n",
      " [14161 14409]\n",
      " [14409 14657]\n",
      " [14657 14905]\n",
      " [14905 15153]\n",
      " [15153 15401]\n",
      " [15401 15649]\n",
      " [15649 15897]\n",
      " [15897 16145]\n",
      " [16145 16393]\n",
      " [16393 16641]\n",
      " [16641 16889]\n",
      " [16889 17137]\n",
      " [17137 17385]\n",
      " [17385 17633]\n",
      " [17633 17881]\n",
      " [17881 18129]\n",
      " [18129 18377]\n",
      " [18377 18625]\n",
      " [18625 18874]\n",
      " [18874 19123]\n",
      " [19123 19372]\n",
      " [19372 19621]\n",
      " [19621 19870]\n",
      " [19870 20118]\n",
      " [20118 20366]\n",
      " [20366 20614]\n",
      " [20614 20862]\n",
      " [20862 21110]\n",
      " [21110 21358]\n",
      " [21358 21607]\n",
      " [21607 21856]\n",
      " [21856 22105]\n",
      " [22105 22354]\n",
      " [22354 22603]\n",
      " [22603 22852]\n",
      " [22852 23101]\n",
      " [23101 23350]\n",
      " [23350 23598]\n",
      " [23598 23846]\n",
      " [23846 24094]\n",
      " [24094 24342]\n",
      " [24342 24590]\n",
      " [24590 24838]]\n"
     ]
    }
   ],
   "source": [
    "# printing the frame ranges that make up each scene\n",
    "scene_frame_indexes = np.array([[0,0]])\n",
    "for i in range(len(zarr_dataset.scenes)):\n",
    "    scene_frame_indexes = np.append(scene_frame_indexes, [[zarr_dataset.scenes[i][0][0], zarr_dataset.scenes[i][0][1]]], axis = 0)\n",
    "    \n",
    "scene_frame_indexes = np.delete(scene_frame_indexes, 0, 0)\n",
    "print(scene_frame_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac1949ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_AV = []\n",
    "for i in range(0, 248):\n",
    "    position_AV.append(ego_dataset[i][\"centroid\"])\n",
    "# for i in range(scene_frame_indexes[0][0], scene_frame_indexes[0][1]):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758cfa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(6, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36,18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.layers(xb)                       \n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)          \n",
    "        # Calcuate loss\n",
    "        loss = F.l1_loss(input = out, target = targets, size_average = None, reduce = None, reduction = 'mean')  \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss = F.l1_loss(input = out, target = targets, size_average = None, reduce = None, reduction = 'mean')    \n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2deb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f314be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate(model, val_loader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "lr = 1e-7\n",
    "history1 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf1ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(inputs)                \n",
    "    prediction = predictions[0].detach()\n",
    "    return target, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb490bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "predictions = []\n",
    "for i in range(len(val_ds)):\n",
    "    input, target = val_ds[i]\n",
    "    target, prediction = predict_single(input, target, model)\n",
    "    targets.append(target)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6700ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax.scatter(range(len(predictions)),targets)\n",
    "ax.scatter(range(len(predictions)), predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d733caf4ffc39d0fbd9a2ba54ef4b7d515956d8048931f8241efe3827fb2d1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
