{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab05d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f33601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea11915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the zarr_dataset\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"../../prediction-dataset/\"\n",
    "cfg = load_config_data(\"./visualisation_config.yaml\")\n",
    "dm = LocalDataManager()\n",
    "dataset_path = dm.require(cfg[\"val_data_loader\"][\"key\"])\n",
    "zarr_dataset = ChunkedDataset(dataset_path)\n",
    "zarr_dataset.open()\n",
    "\n",
    "# using EgoDataset interface to extract AV data\n",
    "rast = build_rasterizer(cfg, dm)\n",
    "ego_dataset = EgoDataset(cfg, zarr_dataset, rast)\n",
    "# agent_dataset = AgentDataset(cfg, zarr_dataset, rast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c971117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the frame ranges that make up each scene\n",
    "scene_frame_indexes = np.array([[0,0]])\n",
    "for i in range(len(zarr_dataset.scenes)):\n",
    "    scene_frame_indexes = np.append(scene_frame_indexes, [[zarr_dataset.scenes[i][0][0], zarr_dataset.scenes[i][0][1]]], axis = 0)\n",
    "    \n",
    "scene_frame_indexes = np.delete(scene_frame_indexes, 0, 0)\n",
    "print(scene_frame_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1949ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_AV = np.array([[0,0]])\n",
    "for i in range(0, 248):\n",
    "    position_AV = np.append(position_AV, [ego_dataset[i][\"centroid\"]], axis = 0)\n",
    "\n",
    "position_AV = np.delete(position_AV, 0, 0)\n",
    "print(position_AV)\n",
    "# for i in range(scene_frame_indexes[0][0], scene_frame_indexes[0][1]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758cfa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(9, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36,18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.layers(xb)                       \n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)          \n",
    "        # Calcuate loss\n",
    "        loss = F.l1_loss(input = out, target = targets, size_average = None, reduce = None, reduction = 'mean')  \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss = F.l1_loss(input = out, target = targets, size_average = None, reduce = None, reduction = 'mean')    \n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2deb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f314be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate(model, val_loader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "lr = 1e-7\n",
    "history1 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf1ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(inputs)                \n",
    "    prediction = predictions[0].detach()\n",
    "    return target, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb490bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "predictions = []\n",
    "for i in range(len(val_ds)):\n",
    "    input, target = val_ds[i]\n",
    "    target, prediction = predict_single(input, target, model)\n",
    "    targets.append(target)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6700ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax.scatter(range(len(predictions)),targets)\n",
    "ax.scatter(range(len(predictions)), predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e7af5626c7e654314ce176c299bd4d61dd6a36e86a9674195997ac339225326"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
